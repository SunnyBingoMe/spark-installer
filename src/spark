#!/bin/bash

source ~/.pam_environment
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.1.0-bin-hadoop2.4.tgz -P $DOWNLOAD_DIR
tar -xzf $DOWNLOAD_DIR/spark-1.2.0-bin-hadoop2.4.tgz -C $DOWNLOAD_DIR
mv $DOWNLOAD_DIR/spark-1.2.0-bin-hadoop2.4 $SPARK_HOME

mv $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh
echo "export SCALA_HOME=$SCALA_HOME" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "export SPARK_WORKER_INSTANCES=3" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "export SPARK_JAR=$SPARK_HOME/lib/spark-assembly-1.1.0-hadoop2.4.0.jar" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "export SPARK_YARN_APP_JAR=$SPARK_HOME/lib/spark-examples-1.1.0-hadoop2.4.0.jar" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "#export SPARK_WORKER_MEMORY=2g" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "#export SPARK_LOCAL_IP=XXXX" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "#export SPARK_MASTER_IP=XXXX" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "#export SPARK_MASTER_WEBUI_PORT=YYYY" | tee -a $SPARK_HOME/conf/spark-env.sh
echo "export PYTHONPATH=$SPARK_HOME/python" | tee -a $SPARK_HOME/conf/spark-env.sh

cd $SPARK_HOME
cp conf/log4j.properties.template conf/log4j.properties
cp $HADOOP_CONF_DIR/slaves $SPARK_HOME/conf/
echo "*********** Spark Done ************"
